{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elementwise Average Fusion model training (with a balanced sampler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root = '../'\n",
    "sys.path.append(root)   # Done to be able to import the packages and functions\n",
    "\n",
    "import Utils.hico_evaluation.evaluation as ev\n",
    "from Utils.custom_loss import MaskedFocalLoss\n",
    "from Utils.annotation_preprocessing import _load_csv_to_tensor\n",
    "from Utils.train_val_split import train_val_split_hico\n",
    "from hoi_classifiers import ElementwiseAvgFusionModel\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_multilabel_balanced_sampler.samplers import LeastSampledClassSampler\n",
    "from Utils.custom_sampler import OverSampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42   #note that the model parameters will still be randomly initiated\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training set:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data:\n",
    "train_data = torch.load(root + \"Embeddings/Combined_Embeddings/train.pt\")\n",
    "train_annotations = _load_csv_to_tensor(root + \"anno/added/anno_augmented_train.csv\").T # Transpose to make both first dimensions the #samples.\n",
    "train_annotations[train_annotations.isnan()] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the training set into a train and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, validation_idx = train_val_split_hico(train_data, train_annotations, 0.2, seed)\n",
    "X_train, X_val = train_data[train_idx], train_data[validation_idx]\n",
    "y_train, y_val = train_annotations[train_idx], train_annotations[validation_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Preparations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size:\n",
    "bs = 512\n",
    "\n",
    "sampler = OverSampler(y_train[:,:600], shuffle = True)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=bs, num_workers=4, sampler=sampler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElementwiseAvgFusionModel(512,655,797)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rfigg\\.conda\\envs\\PyTorch\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "classweights = torch.cat((torch.ones(600),torch.ones(197)*0.5)).to(device)      # The hoi classes weigh twice as much as the seperate classes\n",
    "criterion = MaskedFocalLoss(ignore_label=0, convert_target_to_01= True, weight=classweights)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200, Loss: 0.013997795329, validation map: 0.024383844363\n",
      "Epoch 002/200, Loss: 0.001866235816, validation map: 0.092249396932\n",
      "Epoch 003/200, Loss: 0.001475972219, validation map: 0.146221988388\n",
      "Epoch 004/200, Loss: 0.001296270434, validation map: 0.175207882334\n",
      "Epoch 005/200, Loss: 0.001227850824, validation map: 0.183509685410\n",
      "Epoch 006/200, Loss: 0.001103619540, validation map: 0.263495649137\n",
      "Epoch 007/200, Loss: 0.000934606927, validation map: 0.307222312805\n",
      "Epoch 008/200, Loss: 0.000846852056, validation map: 0.331215859533\n",
      "Epoch 009/200, Loss: 0.000803013905, validation map: 0.341410857374\n",
      "Epoch 010/200, Loss: 0.000785706907, validation map: 0.343065776022\n",
      "Epoch 011/200, Loss: 0.000762604626, validation map: 0.363363437710\n",
      "Epoch 012/200, Loss: 0.000718348669, validation map: 0.378054205920\n",
      "Epoch 013/200, Loss: 0.000687883990, validation map: 0.386562536902\n",
      "Epoch 014/200, Loss: 0.000670109478, validation map: 0.390732933471\n",
      "Epoch 015/200, Loss: 0.000659810636, validation map: 0.392045433003\n",
      "Epoch 016/200, Loss: 0.000653476396, validation map: 0.403995238093\n",
      "Epoch 017/200, Loss: 0.000630079963, validation map: 0.410904606845\n",
      "Epoch 018/200, Loss: 0.000615464594, validation map: 0.415167650949\n",
      "Epoch 019/200, Loss: 0.000599447134, validation map: 0.417666072799\n",
      "Epoch 020/200, Loss: 0.000594824848, validation map: 0.418195651160\n",
      "Epoch 021/200, Loss: 0.000594311599, validation map: 0.424322715439\n",
      "Epoch 022/200, Loss: 0.000578218290, validation map: 0.430850675101\n",
      "Epoch 023/200, Loss: 0.000564969903, validation map: 0.432766456089\n",
      "Epoch 024/200, Loss: 0.000555234349, validation map: 0.434950068294\n",
      "Epoch 025/200, Loss: 0.000548227807, validation map: 0.435195710025\n",
      "Epoch 026/200, Loss: 0.000550639012, validation map: 0.439488962106\n",
      "Epoch 027/200, Loss: 0.000540325160, validation map: 0.443205566450\n",
      "Epoch 028/200, Loss: 0.000529348669, validation map: 0.444876251866\n",
      "Epoch 029/200, Loss: 0.000519788408, validation map: 0.445840829525\n",
      "Epoch 030/200, Loss: 0.000515138021, validation map: 0.445869672068\n",
      "Epoch 031/200, Loss: 0.000517751954, validation map: 0.449605667349\n",
      "Epoch 032/200, Loss: 0.000510014116, validation map: 0.453150777685\n",
      "Epoch 033/200, Loss: 0.000498436869, validation map: 0.454822797560\n",
      "Epoch 034/200, Loss: 0.000490634726, validation map: 0.455772661841\n",
      "Epoch 035/200, Loss: 0.000486260686, validation map: 0.455886809247\n",
      "Epoch 036/200, Loss: 0.000490591614, validation map: 0.457709714186\n",
      "Epoch 037/200, Loss: 0.000483965349, validation map: 0.459361380084\n",
      "Epoch 038/200, Loss: 0.000474860143, validation map: 0.460006417172\n",
      "Epoch 039/200, Loss: 0.000467461596, validation map: 0.461088361227\n",
      "Epoch 040/200, Loss: 0.000463281774, validation map: 0.461100583851\n",
      "Epoch 041/200, Loss: 0.000466796110, validation map: 0.463022806499\n",
      "Epoch 042/200, Loss: 0.000460796255, validation map: 0.463172954780\n",
      "Epoch 043/200, Loss: 0.000452082746, validation map: 0.464284523852\n",
      "Epoch 044/200, Loss: 0.000446524793, validation map: 0.464536806759\n",
      "Epoch 045/200, Loss: 0.000440282633, validation map: 0.464764843357\n",
      "Epoch 046/200, Loss: 0.000447399882, validation map: 0.465867800960\n",
      "Epoch 047/200, Loss: 0.000440486834, validation map: 0.466987875338\n",
      "Epoch 048/200, Loss: 0.000433007731, validation map: 0.466775170418\n",
      "Epoch 049/200, Loss: 0.000426539817, validation map: 0.467801255467\n",
      "Epoch 050/200, Loss: 0.000422883673, validation map: 0.468047852441\n",
      "Epoch 051/200, Loss: 0.000429535684, validation map: 0.469413211266\n",
      "Epoch 052/200, Loss: 0.000423129809, validation map: 0.469885247859\n",
      "Epoch 053/200, Loss: 0.000415616092, validation map: 0.469728979598\n",
      "Epoch 054/200, Loss: 0.000409419865, validation map: 0.470540246202\n",
      "Epoch 055/200, Loss: 0.000404705228, validation map: 0.470444754434\n",
      "Epoch 056/200, Loss: 0.000412807108, validation map: 0.471658614490\n",
      "Epoch 057/200, Loss: 0.000407227941, validation map: 0.471961754719\n",
      "Epoch 058/200, Loss: 0.000399023926, validation map: 0.472871715983\n",
      "Epoch 059/200, Loss: 0.000394109173, validation map: 0.473029016757\n",
      "Epoch 060/200, Loss: 0.000388526902, validation map: 0.473102487483\n",
      "Epoch 061/200, Loss: 0.000395876211, validation map: 0.472827259137\n",
      "Epoch 062/200, Loss: 0.000389877771, validation map: 0.472659118359\n",
      "Epoch 063/200, Loss: 0.000383728902, validation map: 0.473298512038\n",
      "Epoch 064/200, Loss: 0.000377161016, validation map: 0.473334116146\n",
      "Epoch 065/200, Loss: 0.000372760332, validation map: 0.473157353223\n",
      "Epoch 066/200, Loss: 0.000381407075, validation map: 0.473343583243\n",
      "Epoch 067/200, Loss: 0.000375518788, validation map: 0.474918643971\n",
      "Epoch 068/200, Loss: 0.000368916418, validation map: 0.475236489272\n",
      "Epoch 069/200, Loss: 0.000363220616, validation map: 0.475447210466\n",
      "Epoch 070/200, Loss: 0.000358916672, validation map: 0.475764408587\n",
      "Epoch 071/200, Loss: 0.000366252808, validation map: 0.474658822740\n",
      "Epoch 072/200, Loss: 0.000362287816, validation map: 0.474910219576\n",
      "Epoch 073/200, Loss: 0.000355412092, validation map: 0.475202222098\n",
      "Epoch 074/200, Loss: 0.000349335554, validation map: 0.475391642886\n",
      "Epoch 075/200, Loss: 0.000344682934, validation map: 0.475238173076\n",
      "Epoch 076/200, Loss: 0.000353972860, validation map: 0.475555604268\n",
      "Epoch 077/200, Loss: 0.000349451274, validation map: 0.477195338390\n",
      "Epoch 078/200, Loss: 0.000342547140, validation map: 0.477666133926\n",
      "Epoch 079/200, Loss: 0.000336556618, validation map: 0.477496421335\n",
      "Epoch 080/200, Loss: 0.000332591199, validation map: 0.477752299943\n",
      "Epoch 081/200, Loss: 0.000340415795, validation map: 0.477748819503\n",
      "Epoch 082/200, Loss: 0.000336117922, validation map: 0.478095217389\n",
      "Epoch 083/200, Loss: 0.000329954147, validation map: 0.478263321154\n",
      "Epoch 084/200, Loss: 0.000323415103, validation map: 0.478281305479\n",
      "Epoch 085/200, Loss: 0.000319884253, validation map: 0.478297444120\n",
      "Epoch 086/200, Loss: 0.000328011885, validation map: 0.477872556688\n",
      "Epoch 087/200, Loss: 0.000323296082, validation map: 0.478129676585\n",
      "Epoch 088/200, Loss: 0.000317807961, validation map: 0.478040306664\n",
      "Epoch 089/200, Loss: 0.000312071039, validation map: 0.478218952308\n",
      "Epoch 090/200, Loss: 0.000307740810, validation map: 0.478518158475\n",
      "Epoch 091/200, Loss: 0.000316709612, validation map: 0.478164998210\n",
      "Epoch 092/200, Loss: 0.000312200348, validation map: 0.477860906667\n",
      "Epoch 093/200, Loss: 0.000306478275, validation map: 0.477919784617\n",
      "Epoch 094/200, Loss: 0.000299997014, validation map: 0.478215485851\n",
      "Epoch 095/200, Loss: 0.000296373709, validation map: 0.478230789369\n",
      "Epoch 096/200, Loss: 0.000305678737, validation map: 0.477318579303\n",
      "Epoch 097/200, Loss: 0.000300482881, validation map: 0.476799226073\n",
      "Epoch 098/200, Loss: 0.000295006936, validation map: 0.476937870832\n",
      "Epoch 099/200, Loss: 0.000288613161, validation map: 0.477036293631\n",
      "Epoch 100/200, Loss: 0.000284195346, validation map: 0.477173209621\n",
      "Epoch 101/200, Loss: 0.000294384208, validation map: 0.477075246527\n",
      "Epoch 102/200, Loss: 0.000290183241, validation map: 0.477522381459\n",
      "Epoch 103/200, Loss: 0.000283400199, validation map: 0.476359731145\n",
      "Epoch 104/200, Loss: 0.000278373322, validation map: 0.476093239734\n",
      "Epoch 105/200, Loss: 0.000273938475, validation map: 0.476492330428\n",
      "Epoch 106/200, Loss: 0.000283336474, validation map: 0.476044424724\n",
      "Epoch 107/200, Loss: 0.000279935098, validation map: 0.475400158074\n",
      "Epoch 108/200, Loss: 0.000273797003, validation map: 0.475557342811\n",
      "Epoch 109/200, Loss: 0.000267852622, validation map: 0.474922162604\n",
      "Epoch 110/200, Loss: 0.000263501549, validation map: 0.474739841932\n",
      "Epoch 111/200, Loss: 0.000273467593, validation map: 0.474985634513\n",
      "Epoch 112/200, Loss: 0.000269741068, validation map: 0.474534069160\n",
      "Epoch 113/200, Loss: 0.000263468034, validation map: 0.474385470947\n",
      "Epoch 114/200, Loss: 0.000257239838, validation map: 0.474510706423\n",
      "Epoch 115/200, Loss: 0.000253291001, validation map: 0.474624393782\n",
      "Epoch 116/200, Loss: 0.000262376509, validation map: 0.473598907725\n",
      "Epoch 117/200, Loss: 0.000259524132, validation map: 0.473035754003\n",
      "Epoch 118/200, Loss: 0.000253966603, validation map: 0.473195691849\n",
      "Epoch 119/200, Loss: 0.000248014945, validation map: 0.473393807968\n",
      "Epoch 120/200, Loss: 0.000244436435, validation map: 0.473479380702\n",
      "Epoch 121/200, Loss: 0.000252652237, validation map: 0.473854887267\n",
      "Epoch 122/200, Loss: 0.000250091754, validation map: 0.473787656026\n",
      "Epoch 123/200, Loss: 0.000244612242, validation map: 0.473307341764\n",
      "Epoch 124/200, Loss: 0.000238966865, validation map: 0.472726297195\n",
      "Epoch 125/200, Loss: 0.000234370421, validation map: 0.472523246273\n",
      "Epoch 126/200, Loss: 0.000244649676, validation map: 0.472829791483\n",
      "Epoch 127/200, Loss: 0.000239907042, validation map: 0.473090944691\n",
      "Epoch 128/200, Loss: 0.000235824650, validation map: 0.473302421918\n",
      "Epoch 129/200, Loss: 0.000229417172, validation map: 0.473344156687\n",
      "Epoch 130/200, Loss: 0.000225299699, validation map: 0.472883419587\n",
      "Epoch 131/200, Loss: 0.000235009984, validation map: 0.472010263294\n",
      "Epoch 132/200, Loss: 0.000231517752, validation map: 0.472563087933\n",
      "Epoch 133/200, Loss: 0.000226658795, validation map: 0.472276050439\n",
      "Epoch 134/200, Loss: 0.000220715526, validation map: 0.472036188287\n",
      "Epoch 135/200, Loss: 0.000217175052, validation map: 0.471722029599\n",
      "Epoch 136/200, Loss: 0.000226577152, validation map: 0.472252795986\n",
      "Epoch 137/200, Loss: 0.000223063498, validation map: 0.471220678521\n",
      "Epoch 138/200, Loss: 0.000217423440, validation map: 0.471253419398\n",
      "Epoch 139/200, Loss: 0.000212535629, validation map: 0.471356479143\n",
      "Epoch 140/200, Loss: 0.000208165320, validation map: 0.471188502066\n",
      "Epoch 141/200, Loss: 0.000217517543, validation map: 0.470699422234\n",
      "Epoch 142/200, Loss: 0.000215098001, validation map: 0.471374708365\n",
      "Epoch 143/200, Loss: 0.000209426827, validation map: 0.470351085974\n",
      "Epoch 144/200, Loss: 0.000203740272, validation map: 0.471299696117\n",
      "Epoch 145/200, Loss: 0.000200253042, validation map: 0.471382925692\n",
      "Epoch 146/200, Loss: 0.000209456752, validation map: 0.470889990432\n",
      "Epoch 147/200, Loss: 0.000207154379, validation map: 0.469584634982\n",
      "Epoch 148/200, Loss: 0.000201507019, validation map: 0.469622090434\n",
      "Epoch 149/200, Loss: 0.000196203913, validation map: 0.469718797821\n",
      "Epoch 150/200, Loss: 0.000192574631, validation map: 0.469495922785\n",
      "Epoch 151/200, Loss: 0.000201329939, validation map: 0.468235107754\n",
      "Epoch 152/200, Loss: 0.000198947805, validation map: 0.469712639043\n",
      "Epoch 153/200, Loss: 0.000193695759, validation map: 0.469527629396\n",
      "Epoch 154/200, Loss: 0.000188982219, validation map: 0.469829326797\n",
      "Epoch 155/200, Loss: 0.000184904631, validation map: 0.470075110329\n",
      "Epoch 156/200, Loss: 0.000193561502, validation map: 0.468414394729\n",
      "Epoch 157/200, Loss: 0.000191461223, validation map: 0.469147737791\n",
      "Epoch 158/200, Loss: 0.000186402568, validation map: 0.468812039178\n",
      "Epoch 159/200, Loss: 0.000181739788, validation map: 0.469005466041\n",
      "Epoch 160/200, Loss: 0.000177499406, validation map: 0.469064697251\n",
      "Epoch 161/200, Loss: 0.000187332640, validation map: 0.468378289184\n",
      "Epoch 162/200, Loss: 0.000183923377, validation map: 0.468282570169\n",
      "Epoch 163/200, Loss: 0.000179800248, validation map: 0.467392210912\n",
      "Epoch 164/200, Loss: 0.000174390390, validation map: 0.467632516744\n",
      "Epoch 165/200, Loss: 0.000170572335, validation map: 0.467981817980\n",
      "Epoch 166/200, Loss: 0.000179973607, validation map: 0.467342851877\n",
      "Epoch 167/200, Loss: 0.000177277304, validation map: 0.467514184845\n",
      "Epoch 168/200, Loss: 0.000172416201, validation map: 0.466648393062\n",
      "Epoch 169/200, Loss: 0.000167254777, validation map: 0.466409859896\n",
      "Epoch 170/200, Loss: 0.000163918813, validation map: 0.466798366069\n",
      "Epoch 171/200, Loss: 0.000173118489, validation map: 0.466598480852\n",
      "Epoch 172/200, Loss: 0.000170393902, validation map: 0.466425498855\n",
      "Epoch 173/200, Loss: 0.000165509696, validation map: 0.466107339768\n",
      "Epoch 174/200, Loss: 0.000161030067, validation map: 0.465723595584\n",
      "Epoch 175/200, Loss: 0.000157333658, validation map: 0.465882838604\n",
      "Epoch 176/200, Loss: 0.000166886315, validation map: 0.465646099009\n",
      "Epoch 177/200, Loss: 0.000163977618, validation map: 0.466141895405\n",
      "Epoch 178/200, Loss: 0.000159423200, validation map: 0.465699029648\n",
      "Epoch 179/200, Loss: 0.000154699126, validation map: 0.466085317879\n",
      "Epoch 180/200, Loss: 0.000151253009, validation map: 0.466079525821\n",
      "Epoch 181/200, Loss: 0.000160071579, validation map: 0.465125530727\n",
      "Epoch 182/200, Loss: 0.000157596984, validation map: 0.465359016073\n",
      "Epoch 183/200, Loss: 0.000153269485, validation map: 0.465933298326\n",
      "Epoch 184/200, Loss: 0.000148825317, validation map: 0.465718307571\n",
      "Epoch 185/200, Loss: 0.000145072170, validation map: 0.465706808789\n",
      "Epoch 186/200, Loss: 0.000154279005, validation map: 0.465270084155\n",
      "Epoch 187/200, Loss: 0.000151849397, validation map: 0.465106636194\n",
      "Epoch 188/200, Loss: 0.000147324605, validation map: 0.464213144489\n",
      "Epoch 189/200, Loss: 0.000142877070, validation map: 0.464662179275\n",
      "Epoch 190/200, Loss: 0.000139832372, validation map: 0.464696424795\n",
      "Epoch 191/200, Loss: 0.000148139983, validation map: 0.464542745113\n",
      "Epoch 192/200, Loss: 0.000145703883, validation map: 0.464874593587\n",
      "Epoch 193/200, Loss: 0.000141588000, validation map: 0.464329230273\n",
      "Epoch 194/200, Loss: 0.000137417974, validation map: 0.464480882572\n",
      "Epoch 195/200, Loss: 0.000134101798, validation map: 0.464644003390\n",
      "Epoch 196/200, Loss: 0.000142274028, validation map: 0.463984465801\n",
      "Epoch 197/200, Loss: 0.000140265454, validation map: 0.463485600168\n",
      "Epoch 198/200, Loss: 0.000135981956, validation map: 0.462934974769\n",
      "Epoch 199/200, Loss: 0.000132003858, validation map: 0.463470459756\n",
      "Epoch 200/200, Loss: 0.000128828878, validation map: 0.463357043840\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "training_loss_per_epoch = np.zeros(200)\n",
    "validation_loss_per_epoch = np.zeros(200)\n",
    "validation_map_per_epoch = np.zeros(200)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(X_val.to(device))\n",
    "        # calculate the validation loss:\n",
    "        validation_loss = criterion(pred, y_val.to(device))\n",
    "        # calculate the validation mAP:\n",
    "        validation_aps = ev.eval_vo(pred[:,:600].T.cpu().detach().numpy(), y_val[:,:600].T.numpy(),600)[0]\n",
    "        nr_val_classes = np.sum(validation_aps != None)\n",
    "        validation_map = np.nansum(validation_aps) / nr_val_classes\n",
    "\n",
    "    # add the losses and mAP to the arrays:\n",
    "    training_loss_per_epoch[epoch] = running_loss / len(train_dataloader)\n",
    "    validation_loss_per_epoch[epoch] = validation_loss\n",
    "    validation_map_per_epoch[epoch] = validation_map\n",
    "\n",
    "    print(f\"Epoch {epoch+1:0{len(str(num_epochs))}}/{num_epochs}, Loss: {running_loss/len(train_dataloader):.12f}, validation map: {validation_map:.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting the training process to select the number of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rfigg\\Documents\\Bachelor Scriptie opdracht\\CLIP on Hico Organised\\Experiments\\ElemenwiseAvgFusionModelTrainingNotebook_oversampler_cosine scheduler_focal loss.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rfigg/Documents/Bachelor%20Scriptie%20opdracht/CLIP%20on%20Hico%20Organised/Experiments/ElemenwiseAvgFusionModelTrainingNotebook_oversampler_cosine%20scheduler_focal%20loss.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m6\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rfigg/Documents/Bachelor%20Scriptie%20opdracht/CLIP%20on%20Hico%20Organised/Experiments/ElemenwiseAvgFusionModelTrainingNotebook_oversampler_cosine%20scheduler_focal%20loss.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m200\u001b[39m), training_loss_per_epoch, color \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39morange\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rfigg/Documents/Bachelor%20Scriptie%20opdracht/CLIP%20on%20Hico%20Organised/Experiments/ElemenwiseAvgFusionModelTrainingNotebook_oversampler_cosine%20scheduler_focal%20loss.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39marange(\u001b[39m200\u001b[39m), validation_loss_per_epoch, color \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(np.arange(200), training_loss_per_epoch, color = \"orange\")\n",
    "plt.plot(np.arange(200), validation_loss_per_epoch, color = \"blue\")\n",
    "# plt.plot(np.arange(100), validation_loss_main_per_epoch, color= \"red\")\n",
    "# plt.plot(np.arange(100), validation_loss_side_per_epoch, color = \"purple\")\n",
    "plt.plot(np.arange(200), validation_map_per_epoch/100, color = \"green\")\n",
    "#plt.hlines(0.010051161982119083, 0, 100 , colors=['black'],linestyles=['dotted'])\n",
    "plt.ylim(0,0.1)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(validation_map_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(validation_loss_per_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
